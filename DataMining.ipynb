{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "batchSize = 1\n",
    "epochs = 10\n",
    "steps = 200\n",
    "enumEpochs = list(range(0, epochs, 1))\n",
    "\n",
    "print(\"Imports!\")\n",
    "classifier=Sequential()   # Intialializing CNN\n",
    "\n",
    "# Convolution Step\n",
    "classifier.add(Convolution2D(32, 3, 3, \n",
    "                             input_shape = (128,128,3), \n",
    "                             activation = 'relu')) # order of  input_shape for tensorflow backend\n",
    "\n",
    "#Pooling Step\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Flattening Step\n",
    "classifier.add(Flatten()) \n",
    "\n",
    "#Full Connection Step\n",
    "classifier.add(Dense(128,activation = 'relu'))\n",
    "classifier.add(Dense(1,activation = 'sigmoid')) #output layer \n",
    "\n",
    "#Compiling CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.save('F:/Workspace/Test/checkpoints/myModel.h5')\n",
    "print(\"Input!\")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path=\"F:/Workspace/Test/input/training_set\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory( path,\n",
    "                                                    target_size=(128, 128),\n",
    "                                                    batch_size=batchSize,\n",
    "                                                    class_mode='binary')\n",
    "print(\"Validation!\")\n",
    "path=\"F:/Workspace/Test/input/validation\"\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(128,128),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=steps, \n",
    "        callbacks = [cp_callback])\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "\n",
    "# plt.plot(enumEpochs, acc, 'b', label='Training')\n",
    "# plt.plot(enumEpochs, val_acc, 'r', label='Validation')\n",
    "# plt.title('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.figure()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "print(\"Teste!\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "path = \"F:/Workspace/Test/input/test\"\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(128,128),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "#predictions =  classifier.predict_generator(test_generator, steps=steps)\n",
    "trueValues = test_generator.classes\n",
    "\n",
    "#first seperate the `test images` and `test labels`\n",
    "#test_images,test_labels = next(test_generator)\n",
    "\n",
    "#get the class indices\n",
    "print(len(trueValues))\n",
    "#test_labels = test_labels[:,0]  #this should give you array of labels\n",
    "\n",
    "predictions = classifier.predict_generator(test_generator,steps = 609,verbose=0)\n",
    "\n",
    "#trueValues = len(predictions)\n",
    "#predictions[:,0]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve (trueValues , predictions)\n",
    "\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"Starting date and time =\", dt_string)\n",
    "\n",
    "classifier=tf.keras.Sequential()   # Intialializing CNN\n",
    "\n",
    "shape = (244, 244, 3)\n",
    "vggModel=tf.keras.applications.VGG16(input_shape=shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "classifier.add(vggModel)\n",
    "\n",
    "#Flattening Step\n",
    "classifier.add(Flatten()) \n",
    "\n",
    "#Full Connection Step\n",
    "classifier.add(Dense(4096,activation = 'relu'))\n",
    "classifier.add(Dense(4096,activation = 'relu'))  \n",
    "classifier.add(Dense(1,activation = 'softmax'))\n",
    "\n",
    "#Compiling CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path=\"F:/Workspace/Test/input/training_set\"\n",
    "\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "epochs = 3\n",
    "steps = 10\n",
    "enumEpochs = list(range(0, epochs, 1))\n",
    "#print(enumEpochs)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory( path,\n",
    "                                                    target_size=(244, 244),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "print(\"Validation!\")\n",
    "path=\"F:/Workspace/Test/input/validation\"\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(244,244),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary')\n",
    "                                              \n",
    "\n",
    "#Quando testar no servidor, alterar para mais épocas e passos\n",
    "history = classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=steps)\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"Finish date and time =\", dt_string)\n",
    "\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.plot(enumEpochs, acc, 'b', label='Training')\n",
    "# plt.plot(enumEpochs, val_acc, 'r', label='Validation')\n",
    "# plt.title('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.figure()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "path = \"F:/Workspace/Test/input/test\"\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(128,128),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "#predictions =  classifier.predict_generator(test_generator, steps=steps)\n",
    "trueValues = test_generator.classes\n",
    "\n",
    "#first seperate the `test images` and `test labels`\n",
    "#test_images,test_labels = next(test_generator)\n",
    "\n",
    "#get the class indices\n",
    "print(len(trueValues))\n",
    "#test_labels = test_labels[:,0]  #this should give you array of labels\n",
    "\n",
    "predictions = classifier.predict_generator(test_generator,steps = 609,verbose=0)\n",
    "\n",
    "#trueValues = len(predictions)\n",
    "#predictions[:,0]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve (trueValues , predictions)\n",
    "\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import applications\n",
    "\n",
    "# This will load the whole VGG16 network, including the top Dense layers.\n",
    "# Note: by specifying the shape of top layers, input tensor shape is forced\n",
    "# to be (224, 224, 3), therefore you can use it only on 224x224 images.\n",
    "#vgg_model = applications.VGG16(weights='imagenet', include_top=True)\n",
    "\n",
    "print(\"VGG16!\")\n",
    "# If you are only interested in convolution filters. Note that by not\n",
    "# specifying the shape of top layers, the input tensor shape is (None, None, 3),\n",
    "# so you can use them for any size of images.\n",
    "#vgg_model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "vgg_model = applications.VGG16(weights='imagenet', include_top=False, classes=2)\n",
    "#print(\"VGG16!\")\n",
    "# If you want to specify input tensor\n",
    "#from keras.layers import Input\n",
    "#input_tensor = Input(shape=(160, 160, 3))\n",
    "#vgg_model = applications.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "# To see the models' architecture and layer names, run the following\n",
    "#vgg_model.summary()\n",
    "\n",
    "#image = load_img()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "print(\"Import\")\n",
    "vgg_model = VGG16()\n",
    "print(\"VGG16\")\n",
    "path = \"F:\\Workspace\\Datasets\\Bus and Car\\Training\\electric bus\\821c1f91.jpg\"\n",
    "print(\"Image\")\n",
    "img = load_img(path, target_size=(224, 224))\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "img = preprocess_input(img)\n",
    "print(\"Prediction\")\n",
    "values = vgg_model.predict(img)\n",
    "#print(len(values[0]))\n",
    "prediction = decode_predictions(values)\n",
    "prediction = prediction[0][0]\n",
    "\n",
    "print('%s (%.2f%%)' % (prediction[1], prediction[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "print(\"Imports\")\n",
    "vgg_model = VGG16()\n",
    "print(\"VGG16\")\n",
    "path = \"F:/Workspace/Test/input/validation\"\n",
    "\n",
    "allValues = []\n",
    "trueValues = []\n",
    "cont = 0\n",
    "\n",
    "for folders in os.listdir(path):\n",
    "    folder = os.path.join(path, folders)\n",
    "    print(folder)\n",
    "    folderValues = []\n",
    "    \n",
    "    for filename in os.listdir(folder):\n",
    "        trueValues.append(cont)\n",
    "        #end = len(filename)\n",
    "        #ext = filename[-4:end]\n",
    "\n",
    "        #if ext != \".png\":\n",
    "        file = os.path.join(folder, filename)\n",
    "\n",
    "        #img = cv2.imread(file)\n",
    "            \n",
    "        img = load_img(file, target_size=(224, 224))\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        img = preprocess_input(img)\n",
    "\n",
    "        values = vgg_model.predict(img)\n",
    "        #print()\n",
    "        prediction = decode_predictions(values)\n",
    "        prediction = prediction[0][0]\n",
    "        predic = np.argmax(values)\n",
    "\n",
    "        print('%s: %s (%.2f%%)' % (filename, prediction[1], prediction[2]*100))\n",
    "        \n",
    "    cont += 1\n",
    "    allValues.append(predic)\n",
    "    \n",
    "#print(allValues)\n",
    "#print(trueValues)\n",
    "#print(len(allValues), len(trueValues))\n",
    "\n",
    "#from sklearn.metrics import roc_curve\n",
    "#y_pred_keras = keras_model.predict(X_test).ravel()\n",
    "#fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPEAMENTO\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "batchSize = 1\n",
    "\n",
    "classifier=tf.keras.Sequential()   # Intialializing CNN\n",
    "\n",
    "shape = (224, 224, 3)\n",
    "vggModel=tf.keras.applications.VGG16(input_shape=shape,\n",
    "                                               include_top=True,\n",
    "                                               weights='imagenet')\n",
    "vggModel.trainable = False\n",
    "classifier.add(vggModel)\n",
    "\n",
    "#classifier.add(Flatten()) \n",
    "classifier.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path=\"input/training_set\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory( path,\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    batch_size=batchSize,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "path=\"input/validation\"\n",
    "\n",
    "validSet = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "epochs = 10\n",
    "steps = len(training_set)/batchSize\n",
    "checkpoint_path = \"checkpoints/cp2.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "validSteps = len(validSet)/batchSize\n",
    "\n",
    "loss, acc = classifier.evaluate_generator(generator=validSet,steps=validSteps)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "history = classifier.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=validSet,\n",
    "    validation_steps=validSteps, \n",
    "    callbacks = [cp])\n",
    "    \n",
    "savePath = 'checkpoints/newDenseModelTeste.h5'\n",
    "classifier.save(savePath) \n",
    "    \n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "accStr = []\n",
    "val_accStr = []\n",
    "lossStr = []\n",
    "val_lossStr = []\n",
    "\n",
    "accStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in acc)\n",
    "val_accStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in val_acc)\n",
    "lossStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in loss)\n",
    "val_lossStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in val_loss)\n",
    "\n",
    "with open('results/history.txt', 'w') as hist:\n",
    "    hist.write(accStr+\"\\n\")\n",
    "    hist.write(val_accStr+\"\\n\")\n",
    "    hist.write(lossStr+\"\\n\")\n",
    "    hist.write(val_lossStr)\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "# path = \"input/test\"\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#                                               path,\n",
    "#                                               target_size=(244,244),\n",
    "#                                               batch_size=batchSize,\n",
    "#                                               class_mode='binary')\n",
    "\n",
    "trueValues = validSet.classes\n",
    "predSteps = len(validSet.classes) / batchSize\n",
    "predictions = classifier.predict_generator(validSet,steps = predSteps,verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve (trueValues , predictions)\n",
    "\n",
    "fprStr = []\n",
    "tprStr = []\n",
    "\n",
    "fprStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in fpr)\n",
    "tprStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in tpr)\n",
    "\n",
    "with open('results/roc.txt', 'w') as curve:\n",
    "    curve.write(fprStr+\"\\n\")\n",
    "    curve.write(tprStr)\n",
    "    \n",
    "truesStr = []\n",
    "predicStr = []\n",
    "\n",
    "truesStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in trueValues )\n",
    "predicStr = \" \".join(str(\"{0:.2f}\".format(i[0])) for i in predictions)\n",
    "\n",
    "with open('results/predictions.txt', 'w+') as curve:\n",
    "    curve.write(truesStr +\"\\n\")\n",
    "    curve.write(predicStr)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "#from keras import optimizers\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batchSize = 16\n",
    "# def createDataset(path):\n",
    "#     imageSet = []\n",
    "#     labels = []\n",
    "#     classes = 0\n",
    "#     for folders in os.listdir(path):\n",
    "#         folder = os.path.join(path, folders)\n",
    "#         print(folder)\n",
    "#         classes = 1\n",
    "#         for filename in os.listdir(folder):\n",
    "#             file = os.path.join(folder, filename)\n",
    "            \n",
    "#             img = load_img(file, target_size=(224, 224))\n",
    "#             img = img_to_array(img)\n",
    "#             img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "#             imageSet.append(img)\n",
    "            \n",
    "#             labels.append(classes)\n",
    "            \n",
    "#     return imageSet, labels\n",
    "\n",
    "def generateTraining(path):\n",
    "    gen = ImageDataGenerator(rescale=1/255)\n",
    "    generator = gen.flow_from_directory(path,\n",
    "                                       target_size=(224,224),\n",
    "                                       batch_size=batchSize,\n",
    "                                       classes = ['bus', 'car'],\n",
    "                                       class_mode='binary')\n",
    "    return generator\n",
    "\n",
    "#def loadModel(classes, layerType):\n",
    "        \n",
    "def loadModel(classes, layerType):\n",
    "    vgg_model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "    inputShape = Input(shape=(224, 224, 3), name = 'image_input') \n",
    "    outputNet = vgg_model(inputShape)\n",
    "\n",
    "    #Add the fully-connected layers \n",
    "    outLayers = Flatten(name='flatten')(outputNet)\n",
    "    outLayers = Dense(4096, activation=layerType, name='fc1')(outLayers)\n",
    "    outLayers = Dense(4096, activation=layerType, name='fc2')(outLayers)\n",
    "    outLayers = Dense(classes, activation='softmax', name='predictions')(outLayers)\n",
    "\n",
    "    newModel = Model(name = 'My Model', inputs = inputShape, outputs = outLayers)\n",
    "    newModel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return newModel        \n",
    "\n",
    "#inputData, labels = createDataset()\n",
    "#inputData = np.array(inputData)\n",
    "#labels = np.array(labels)\n",
    "\n",
    "\n",
    "#trainData, trainValue, labelsData, labelsValue = train_test_split(inputData, labels, test_size = 0.20, random_state = 2)\n",
    "#print('Conjunto')\n",
    "trainingSet = generateTraining('F:/data/train/')\n",
    "#print('Modelo')\n",
    "myModel = loadModel(2, 'relu')\n",
    "#myModel = VGG16(weights='imagenet', include_top=True)\n",
    "myModel.summary()\n",
    "#myModel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print('Treino')\n",
    "#samples = trainset\n",
    "history = myModel.fit_generator(trainingSet,\n",
    "                                 steps_per_epoch=int(trainingSet.samples/batchSize),\n",
    "                                 epochs = 16,\n",
    "                                 verbose = 1)\n",
    "#print('Treinado')\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "batchSize = 1\n",
    "\n",
    "print(\"Imports\")\n",
    "classifier=tf.keras.Sequential()   # Intialializing CNN\n",
    "\n",
    "shape = (244, 244, 3)\n",
    "vggModel=tf.keras.applications.VGG16(input_shape=shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "classifier.add(vggModel)\n",
    "\n",
    "#Flattening Step\n",
    "classifier.add(Flatten()) \n",
    "\n",
    "#Full Connection Step\n",
    "classifier.add(Dense(4096,activation = 'relu'))\n",
    "classifier.add(Dense(4096,activation = 'relu'))  \n",
    "classifier.add(Dense(1,activation = 'softmax'))\n",
    "\n",
    "#Compiling CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path=\"F:/Workspace/Test/input/training_set\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory( path,\n",
    "                                                    target_size=(244, 244),\n",
    "                                                    batch_size=batchSize,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "path=\"F:/Workspace/Test/input/validation\"\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(244,244),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"Starting date and time =\", dt_string)\n",
    "\n",
    "epochs = 50\n",
    "steps = 100\n",
    "checkpoint_path = \"F:/Workspace/Test/input/checkpoints/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "#Quando testar no servidor, alterar para mais épocas e passos\n",
    "history = classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=steps, \n",
    "        callbacks = [cp])\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"Finish date and time =\", dt_string)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "path = \"F:/Workspace/Test/input/test\"\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(244,244),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "trueValues = test_generator.classes\n",
    "\n",
    "predictions = classifier.predict_generator(test_generator,steps = 609,verbose=0)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve (trueValues , predictions)\n",
    "\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "\n",
    "batchSize = 32\n",
    "\n",
    "print(\"Imports\")\n",
    "classifier=tf.keras.Sequential()   # Intialializing CNN\n",
    "\n",
    "shape = (244, 244, 3)\n",
    "vggModel=tf.keras.applications.VGG16(input_shape=shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "classifier.add(vggModel)\n",
    "\n",
    "#Flattening Step\n",
    "classifier.add(Flatten()) \n",
    "\n",
    "#Full Connection Step\n",
    "classifier.add(Dense(4096,activation = 'relu'))\n",
    "classifier.add(Dense(4096,activation = 'relu'))  \n",
    "classifier.add(Dense(1,activation = 'softmax'))\n",
    "\n",
    "#Compiling CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path=\"F:/Workspace/Test/input/training_set\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory( path,\n",
    "                                                    target_size=(244, 244),\n",
    "                                                    batch_size=batchSize,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "path=\"F:/Workspace/Test/input/validation\"\n",
    "\n",
    "validSet = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(244,244),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"Starting date and time =\", dt_string)\n",
    "epochs = 1\n",
    "steps = 50\n",
    "checkpoint_path = \"F:/Workspace/Test/checkpoints/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "#Quando testar no servidor, alterar para mais épocas e passos\n",
    "validSteps = 20\n",
    "\n",
    "\n",
    "\n",
    "loss, acc = classifier.evaluate_generator(generator=validSet,steps=steps)\n",
    "\n",
    "#loss, acc = classifier.evaluate(validSet,  validSet.classes, verbose=2)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "\n",
    "for i in range(5): \n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    classifier.load_weights(latest)\n",
    "    \n",
    "    history = classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=epochs,\n",
    "        validation_data=validSet,\n",
    "        validation_steps=validSteps, \n",
    "        callbacks = [cp])\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "    savePath = 'F:/Workspace/Test/checkpoints/myModel{epoch:04d}.h5'\n",
    "    classifier.save(savePath.format(epoch=i)) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"Finish date and time =\", dt_string)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "path = \"F:/Workspace/Test/input/test\"\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                              path,\n",
    "                                              target_size=(244,244),\n",
    "                                              batch_size=batchSize,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "\n",
    "trueValues = test_generator.classes\n",
    "predSteps = len(test_generator.classes) / batchSize\n",
    "predictions = classifier.predict_generator(test_generator,steps = predSteps,verbose=0)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve (trueValues , predictions)\n",
    "\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "print(\"start\")\n",
    "fpr = [0,0.14492754,0.15942029,0.20289855,0.21014493,0.24637681\n",
    ",0.24637681,0.26086957,0.26811594,0.2826087,0.2826087,0.2826087\n",
    ",0.28985507,0.28985507,0.28985507,0.28985507,0.29710145,0.30434783\n",
    ",0.30434783,0.3115942,0.31884058,0.32608696,0.33333333,0.33333333\n",
    ",0.34057971,0.34057971,0.34057971,0.34782609,0.34782609,0.35507246\n",
    ",0.35507246,0.35507246,0.36956522,0.36956522,0.36956522,0.36956522\n",
    ",0.37681159,0.37681159,0.38405797,0.38405797,0.38405797,0.38405797\n",
    ",0.39130435,0.39130435,0.39855072,0.39855072,0.39855072,0.41304348\n",
    ",0.41304348,0.42753623,0.42753623,0.42753623,0.42753623,0.43478261\n",
    ",0.43478261,0.46376812,0.46376812,0.47826087,0.47826087,0.48550725\n",
    ",0.48550725,0.5,0.5,0.52173913,0.52173913,0.52898551\n",
    ",0.52898551,0.53623188,0.53623188,0.54347826,0.54347826,0.55072464\n",
    ",0.55072464,0.55797101,0.55797101,0.56521739,0.56521739,0.57246377\n",
    ",0.57246377,0.57971014,0.57971014,0.58695652,0.58695652,0.5942029\n",
    ",0.5942029,0.60144928,0.60144928,0.60869565,0.60869565,0.62318841\n",
    ",0.62318841,0.63043478,0.63043478,0.63768116,0.63768116,0.64492754\n",
    ",0.64492754,0.65217391,0.65217391,0.65942029,0.65942029,0.66666667\n",
    ",0.66666667,0.67391304,0.67391304,0.68115942,0.68115942,0.6884058\n",
    ",0.6884058,0.69565217,0.69565217,0.70289855,0.70289855,0.71014493\n",
    ",0.71014493,0.7173913,0.7173913,0.72463768,0.72463768,0.73188406\n",
    ",0.73188406,0.73913043,0.73913043,0.75362319,0.75362319,0.76086957\n",
    ",0.76086957,0.76811594,0.76811594,0.77536232,0.77536232,0.7826087\n",
    ",0.7826087,0.78985507,0.78985507,0.80434783,0.80434783,0.8115942\n",
    ",0.8115942,0.82608696,0.82608696,0.83333333,0.83333333,0.84057971\n",
    ",0.84057971,0.84782609,0.84782609,0.84782609,0.84782609,0.85507246\n",
    ",0.85507246,0.86231884,0.86231884,0.86231884,0.86231884,0.86956522\n",
    ",0.86956522,0.88405797,0.9057971,0.9057971,1]\n",
    "\n",
    "tpr = [0,0.18259023,0.19957537,0.24416136,0.24840764,0.28025478\n",
    ",0.28450106,0.29511677,0.29936306,0.30573248,0.31847134,0.32059448\n",
    ",0.32059448,0.32271762,0.32696391,0.33757962,0.3418259,0.34394904\n",
    ",0.34607219,0.34819533,0.35244161,0.35244161,0.3566879,0.36730361\n",
    ",0.36942675,0.37367304,0.37791932,0.38216561,0.40127389,0.40339703\n",
    ",0.40764331,0.4118896,0.4118896,0.42250531,0.42675159,0.42887473\n",
    ",0.42887473,0.43949045,0.43949045,0.44161359,0.44585987,0.45010616\n",
    ",0.45010616,0.46072187,0.46072187,0.4670913,0.48407643,0.48407643\n",
    ",0.49044586,0.49044586,0.50106157,0.50530786,0.507431,0.507431\n",
    ",0.50955414,0.50955414,0.51592357,0.51592357,0.51804671,0.51804671\n",
    ",0.52016985,0.52016985,0.52441614,0.52441614,0.52653928,0.52653928\n",
    ",0.52866242,0.52866242,0.53503185,0.53503185,0.53927813,0.53927813\n",
    ",0.54140127,0.54140127,0.54564756,0.54564756,0.55838641,0.55838641\n",
    ",0.56050955,0.56050955,0.56900212,0.56900212,0.57112527,0.57112527\n",
    ",0.57537155,0.57537155,0.60509554,0.60509554,0.60721868,0.60721868\n",
    ",0.61783439,0.61783439,0.62420382,0.62420382,0.62632696,0.62632696\n",
    ",0.63694268,0.63694268,0.65392781,0.65392781,0.67303609,0.67303609\n",
    ",0.67515924,0.67515924,0.67940552,0.67940552,0.68577495,0.68577495\n",
    ",0.69639066,0.69639066,0.6985138,0.6985138,0.70700637,0.70700637\n",
    ",0.7133758,0.7133758,0.71762208,0.71762208,0.72399151,0.72399151\n",
    ",0.73460722,0.73460722,0.74309979,0.74309979,0.77494692,0.77494692\n",
    ",0.78343949,0.78343949,0.81953291,0.81953291,0.82165605,0.82165605\n",
    ",0.82377919,0.82377919,0.83014862,0.83014862,0.83227176,0.83227176\n",
    ",0.84288747,0.84288747,0.86836518,0.86836518,0.87261146,0.87473461\n",
    ",0.87685775,0.87898089,0.88322718,0.88747346,0.8895966,0.89171975\n",
    ",0.89808917,0.90021231,0.91295117,0.91932059,0.92781316,0.93205945\n",
    ",0.9447983,0.94904459,0.95329087,0.96602972,1]\n",
    "\n",
    "fprStr = []\n",
    "tprStr = []\n",
    "\n",
    "\n",
    "fprStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in fpr)\n",
    "tprStr = \" \".join(str(\"{0:.2f}\".format(i)) for i in tpr)\n",
    "\n",
    "\n",
    "\n",
    "with open('roc.txt', 'w') as curve:\n",
    "    #for listitem in places:\n",
    "    curve.write(fprStr+\"\\n\")\n",
    "    curve.write(tprStr)\n",
    "\n",
    "# print(fpr)\n",
    "# print(tpr)\n",
    "print(\"finish\")\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = []\n",
    "val_acc = []\n",
    "loss = []\n",
    "val_loss = []\n",
    "\n",
    "with open('results/history.txt', 'r') as filehandle:\n",
    "    accStr = filehandle.readline()\n",
    "    val_accStr = filehandle.readline()\n",
    "    lossStr = filehandle.readline()\n",
    "    val_lossStr = filehandle.readline()\n",
    "\n",
    "data = accStr.split()\n",
    "for i in data:\n",
    "    acc.append(float(i))\n",
    "print(acc)\n",
    "\n",
    "data = val_accStr.split()\n",
    "for i in data:\n",
    "    val_acc.append(float(i))\n",
    "print(val_acc)\n",
    "    \n",
    "data = lossStr.split()\n",
    "for i in data:\n",
    "    loss.append(float(i))\n",
    "\n",
    "data = val_lossStr.split()\n",
    "for i in data:\n",
    "    val_loss.append(float(i))\n",
    "\n",
    "epochs = [i for i in range(len(acc))]\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open('results/roc.txt', 'r') as filehandle:\n",
    "    fprStr = filehandle.readline()\n",
    "    tprStr = filehandle.readline()\n",
    "\n",
    "data = fprStr.split()\n",
    "for i in data:\n",
    "    fpr.append(float(i))\n",
    "\n",
    "data = tprStr.split()\n",
    "for i in data:\n",
    "    tpr.append(float(i))\n",
    "\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "print(\"Started!\")\n",
    "\n",
    "\n",
    "def createModel():\n",
    "    model=tf.keras.Sequential()   # Intialializing CNN\n",
    "\n",
    "    shape = (244, 244, 3)\n",
    "    vggModel=tf.keras.applications.VGG16(input_shape=shape,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "    vggModel.trainable = False\n",
    "    model.add(vggModel)\n",
    "\n",
    "    model.add(Flatten()) \n",
    "\n",
    "    model.add(Dense(4096,activation = 'relu'))\n",
    "    model.add(Dense(4096,activation = 'relu'))  \n",
    "    model.add(Dense(1,activation = 'softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "classifier = createModel()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "path=\"F:/Workspace/Test/input/validation\"\n",
    "\n",
    "batchSize = 16\n",
    "\n",
    "\n",
    "validSet = test_datagen.flow_from_directory(path,\n",
    "                                              target_size=(244,244),\n",
    "                                              batch_size=batchSize,\n",
    "                                              shuffle=False,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "\n",
    "checkpoint_path = \"F:/Workspace/Test/checkpoints/old/cpOld.ckpt\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "steps = len(validSet.classes) / batchSize                   \n",
    "\n",
    "#loss, acc = classifier.evaluate_generator(generator=validSet,steps=steps)\n",
    "#print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "classifier.load_weights(checkpoint_path)\n",
    "loss, acc = classifier.evaluate_generator(generator=validSet,steps=steps)\n",
    "print(\"Loaded model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "trueValues = validSet.classes\n",
    "predSteps = len(validSet.classes) / batchSize\n",
    "predictions = classifier.predict_generator(validSet,steps = predSteps,verbose=1)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve (trueValues , predictions)\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open('checkpoints/results/roc.txt', 'r') as filehandle:\n",
    "    fprStr = filehandle.readline()\n",
    "    tprStr = filehandle.readline()\n",
    "\n",
    "data = fprStr.split()\n",
    "for i in data:\n",
    "    fpr.append(float(i))\n",
    "\n",
    "data = tprStr.split()\n",
    "for i in data:\n",
    "    tpr.append(float(i))\n",
    "\n",
    "print(auc(fpr, tpr))\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open('checkpoints/results/rocOld.txt', 'r') as filehandle:\n",
    "    fprStr = filehandle.readline()\n",
    "    tprStr = filehandle.readline()\n",
    "\n",
    "data = fprStr.split()\n",
    "for i in data:\n",
    "    fpr.append(float(i))\n",
    "\n",
    "data = tprStr.split()\n",
    "for i in data:\n",
    "    tpr.append(float(i))\n",
    "\n",
    "print(auc(fpr, tpr))\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open('checkpoints/results/roc.txt', 'r') as filehandle:\n",
    "    fprStr = filehandle.readline()\n",
    "    tprStr = filehandle.readline()\n",
    "\n",
    "data = fprStr.split()\n",
    "for i in data:\n",
    "    fpr.append(float(i))\n",
    "\n",
    "data = tprStr.split()\n",
    "for i in data:\n",
    "    tpr.append(float(i))\n",
    "\n",
    "print(auc(fpr, tpr))\n",
    "plt.plot(fpr,tpr) \n",
    "plt.axis([0,1,0,1]) \n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "print(\"Started!\")\n",
    "batchSize = 16\n",
    "\n",
    "\n",
    "\n",
    "classifier = tf.keras.models.load_model('F:/Workspace/Test/checkpoints/myModel.h5')\n",
    "classifier.summary()\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "path=\"F:/Workspace/Test/input/validation\"\n",
    "\n",
    "validSet = test_datagen.flow_from_directory(path,\n",
    "                                              target_size=(244,244),\n",
    "                                              batch_size=batchSize,\n",
    "                                              shuffle=False,\n",
    "                                              class_mode='binary')\n",
    "\n",
    "\n",
    "#checkpoint_path = \"F:/Workspace/Test/checkpoints/cp2.ckpt\"\n",
    "#checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "                              \n",
    "#loss, acc = classifier.evaluate_generator(generator=validSet,steps=steps)\n",
    "#print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "predSteps = len(validSet.classes) / batchSize\n",
    "#classifier.load_weights(checkpoint_path)\n",
    "loss, acc = classifier.evaluate_generator(generator=validSet,steps=predSteps)\n",
    "print(\"Loaded model, accuracy: {:5.2f}%\".format(100*acc))\n",
    "\n",
    "from sklearn.metrics import roc_curve#,roc_auc_score\n",
    "\n",
    "trueValues = validSet.classes\n",
    "\n",
    "predictions = classifier.predict_generator(validSet,steps = predSteps,verbose=2)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve (trueValues , predictions)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.axis([0,1,0,1])\n",
    "plt.xlabel('False Positive Rate') \n",
    "plt.ylabel('True Positive Rate') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
